{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH1. 컴퓨터는 데이터에서 배운다.\n",
    "*머신러닝은 데이터를 이해하는 알고리즘의 과학이자 어플리케이션입니다.*  \n",
    "\n",
    "이 장에서는 다음 주제를 다룹니다.\n",
    "- 머신 러닝의 일반적 개념 이해하기.\n",
    "- 세 종류의 학습과 기본용어 알아보기\n",
    "- 성공적인 머신 러닝 시스템을 설계하는 필수 요소 알아보기\n",
    "- 데이터 분석과 머신 러닝을 위한 파이썬을 설치하고 설정하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 데이터를 지식으로 바꾸는 지능적인 시스템 구축\n",
    "정형 또는 비정형 데이터가 매우 풍부한 시대 -> 데이터에서 지식을 추출하여 예측하는 자기 학습 알고리즘과 관련된 인공지능의 하위 분야로 머신 러닝이 출현했습니다.  \n",
    "사람이 수동으로 데이터 분석 -> 머신 러닝이 데이터에서 더 효율적으로 지식을 추출하여 예측 모델과 데이터 기반 의사결정  \n",
    "스팸 필터, 편리한 텍스트와 음성 인식 소프트웨어, 믿을 수 있는 웹 검색 엔진 등의 기술의 향상을 이끌었습니다.\n",
    "\n",
    "### 1.2 머신 러닝의 세 가지 종류\n",
    "##### 지도학습, 비지도학습, 강화 학습\n",
    "1. 지도학습 -> 레이블된 데이터, 직접 피드백, 출력 및 미래 예측\n",
    "2. 비지도학습 -> 레이블 및 타깃 없음, 피드백 없음, 데이터에서 숨겨진 구조 찾기\n",
    "3. 강화 학습 -> 결정 과정, 보상 시스템, 연속된 행동에서 학습\n",
    "\n",
    "#### 1.2.1 지도학습으로 미래 예측\n",
    "- 주요 목적 : 레이블된 훈련 데이터에서 모델을 학습하여 본 적 없는 미래 데이터에 대해 에측을 만드는 것\n",
    "- 지도(supervised) : 희망하는 출력 신호(레이블)가 있는 일련의 샘플을 의미\n",
    "- ex) 스팸 이메일 : 레이블된 이메일 데이터셋에서 지도 학습 머신 러닝을 알고리즘을 사용하여 모델을 훈련   \n",
    "                    -> 훈련된 모델은 새로운 이메일이 두 개의 범주 중 어디에 속하는지 예측\n",
    "- 개별 클래스 레이블이 있는 지도학습을 분류, 연속적인 값을 출력하는 지도학습을 회귀\n",
    "\n",
    "#### 분류 : 클래스 레이블 예측\n",
    "*과거의 관측을 기반으로 새로운 샘플의 범주형 클래스 레이블을 예측하는 것이 목적 - 클래스 레이블은 이산적*  \n",
    "\n",
    "앞의 스팸 이메일은 *이진분류*  \n",
    "두 개 이상의 클래스 레이블을 가진 경우 *다중 분류* - 전형적인 예 : 손으로 쓴 글자 인식  \n",
    "\n",
    "지도 학습 알고리즘은 데이터 셋을 이용하여 클래스를 구분할 수 있는 규칙을 학습 -> 이 규칙은 결정 경계(decision boundary) \n",
    "\n",
    "#### 회귀 : 연속적인 출력 값 예측\n",
    "*예측 변수(또는 설명 변수, 입력)와 연속적인 반응 변수(또는 출력, 타깃)가 주어졌을 때 출력 값을 예측하는 두 변수 사이의 관계를 찾습니다*\n",
    "\n",
    "EX) 시험공부에 투자한 시간과 최종 점수 사이에 관계가 있다면 두 값으로 훈련 데이터를 만들고 모델을 학습할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 강화 학습으로 반응형 문제 해결\n",
    "*강화 학습은 머신 러닝의 또 다른 종류입니다.*  \n",
    "- 목적 : 환경과 상호 작용하여 시스템(에이전트) 성능을 향상하는 것\n",
    "         환경의 현재 상태 정보는 보상 신호를 포함 -> 강화 학습을 지도 학습분야로 생각 가능\n",
    "- 강화 학습의 피드백은 정답 레이블이나 값 X. -> 보상 함수로 얼마나 행동이 좋은지 측정한 값\n",
    "- 탐험적인 시행착오 방식이나 신중하게 세운 계획을 사용  \n",
    "EX) 체스게임 : 에이전트는 체스판의 상태(환경0에 따라 기물의 이동을 결정 -> 보상은 게임이 종료했을 때 승리하거나 패배하는 것으로 정의\n",
    "\n",
    "- 여러 하위 분야가 존재 : 일반적인 구조 - 강화 학습 에이전트가 환경과 상호작용하여 보상을 최대하는 것 ( 보상은 양의 보상이나 음의 보상으로 연관)\n",
    "\n",
    "#### 1.2.3 비지도 학습으로 숨겨진 구조 발견\n",
    "*비지도 학습에서는 레이블되지 않거나 구조를 알 수 없는 데이터를 다룸*  \n",
    "*알려진 출력 값이나 보상 함수의 도움을 받지 않고 의미 있는 정보를 추출하기 위해 데이터 구조 탐색 가능*\n",
    "\n",
    "#### 군집 : 서브그룹 찾기\n",
    "*군집(clustering)은 사전 정보 없이 쌓여 있는 그룹 정보를 의미 있는 서브그룹 또는 클러스터로 조직하는 탐색적 데이터 분석 기법*  \n",
    "*분석 과정에서 만든 각 클러스터는 어느 정도 유사성을 공유하고 다른 클러스터와는 비슷하지 않는 샘플 그룹을 형성*  \n",
    "***비지도 분류*** - 클러스터링은 정보를 조직화하고 데이터에서 의미 있는 관계를 유도하는 훌륭한 도구입니다.  \n",
    "마케팅에 유용\n",
    "\n",
    "#### 차원 축소 : 데이터 압축\n",
    "하나의 관측 샘플에 많은 측정 지표가 존재 - > 머신 러닝 알고리즘의 계산 성능과 저장 공간의 한게에 맞닥뜨릴 수 있습니다.  \n",
    "                                        - > 비지도 차원 축소는 잡음 데이터를 제거하귀 위해 특성 전처리 단계에서 종종 적용하는 방법.  \n",
    "***차원 축소***는 관련 있는 정보를 대부분 유지하면서 더 작은 차원의 부분 공간으로 데이터를 압축  \n",
    "데이터 시각화에도 유용 - 산점도나 히스토그램 등 \n",
    "                                        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 기본 용어와 표기법 소개\n",
    "샘플 :  데이터셋에서 하나의 행  \n",
    "열 : 데이터셋의 특성  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 머신 러닝 시스템 구축 로드맵\n",
    " \n",
    "***전처리 -> 학습 -> 평가 -> 예측***\n",
    " \n",
    "#### 1.4.1 전처리: 데이터 형태 갖추기\n",
    "- 원본 데이터의 형태와 모습이 학습 알고리즘이 최적의 성능을 내기에 적합한 경우는 매우 드뭄\n",
    "- ***데이터 전처리는 모든 머신 러닝 어플리케이션에서 가장 중요한 단계 중 하나***  \n",
    "        최적의 성능을 위해선 선택된 특성이 같은 스케을 가져야 함 -> 특성을 [0,1] 범위로 변환하거나 표준 정규 분포로 변환하는 경우가 많음\n",
    "        중복된 정보 제거\n",
    "        특정 공간의 차원을 축소 - 잡음 데이터가 있을 경우 성능도 증가\n",
    "        \n",
    "#### 1.4.2 예측 모델과 훈련과 선택\n",
    "- 머신 러닝 알고리즘은 각기 다른 문제를 해결하기 위해 개발  \n",
    "    '가진 도구가 망치밖에 없다면 모든 문제가 못으로 보일 것입니다'   \n",
    "    예를 들어 분류 알고리즘은 태생적인 편향이 있음 -> 작업에서 아무런 가정도 하지 않는다면 어떤 하나의 분류 모델이 더 우월하다고 말할 수 없음  \n",
    "    현실에선 가장 좋은 모델을 훈련하고 선택하기 위해선 최소한 몇가지 알고리즘을 비교  \n",
    "    비교 기준은 ***정확도***(분류된 샘플 비율) \n",
    "    훈련 데이터와 검증 데이터를 따로 보관시 -> 교차 검증(훈련 데이터를 훈련 세트와 검증 세트로 나눔)  \n",
    "    라이브러리가 무조건 적인 답은 아님 -> 다음 장에서 하이퍼파라미터 최적화 기법을 많이 사용  \n",
    "    \n",
    "#### 1.4.3 모델을 평가하고 본 적 없는 샘플로 예측\n",
    "- 검증 데이터를 사용시 일반화 오차를 예상 -> 성능에 만족 시 이 모델을 사용하여 미래의 새로운 데이터를 예측\n",
    "- 이전에 언급한 특성 스케일 조정과 차원 축소 같은 단계에서 사용한 파라미터는 훈련 세트만 사용하여 얻은 것임에 주목해야 함\n",
    "        -> 나중에 동일한 파라미터를 테스트 세트는 물론 새로운 모든 샘플을 변환하는데 사용합니다.\n",
    "          -> 그렇지 않으면 테스트 세트에서 측정한 성능은 과도하게 낙관적인 결과가 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
